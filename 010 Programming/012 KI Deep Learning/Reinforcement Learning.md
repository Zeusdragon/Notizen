
**Tags:** #reinforcement-learning #deep-learning #ai #agents
**Status:** üü° In Bearbeitung

---

## 1. Definition
Reinforcement Learning ist ein Teilgebiet des Machine Learning, bei dem ein **Agent** lernt, Entscheidungen zu treffen, indem er mit einer **Umgebung** (Environment) interagiert. Ziel ist es, die kumulative Belohnung (Reward) √ºber die Zeit zu maximieren.


## 2. Der RL-Loop (Markov Decision Process)
Der Prozess wird formal oft als MDP (Markov Decision Process) beschrieben:

1.  **State ($S_t$):** Der Agent beobachtet den aktuellen Zustand der Umgebung.
2.  **Action ($A_t$):** Basierend auf seiner Strategie (**Policy $\pi$**) w√§hlt der Agent eine Aktion.
3.  **Reward ($R_{t+1}$):** Die Umgebung gibt Feedback, ob die Aktion gut oder schlecht war.
4.  **Next State ($S_{t+1}$):** Die Umgebung wechselt in einen neuen Zustand.

## 3. Wichtige Konzepte

### Policy ($\pi$)
Die Strategie des Agenten.
* **Deterministisch:** $a = \pi(s)$ (Immer gleiche Aktion bei gleichem Zustand).
* **Stochastisch:** $\pi(a|s)$ (Wahrscheinlichkeitsverteilung √ºber Aktionen).

### Value Function ($V(s)$) & Q-Function ($Q(s, a)$)
* **Value:** Wie gut ist es, in Zustand $s$ zu sein? (Erwarteter zuk√ºnftiger Reward).
* **Q-Value:** Wie gut ist es, in Zustand $s$ die Aktion $a$ zu w√§hlen?
    * Deep Q-Learning (DQN) nutzt ein Neural Network, um diese Q-Werte zu sch√§tzen.

### Exploration vs. Exploitation
Das zentrale Dilemma im RL:
* **Exploration:** Neue Dinge ausprobieren, um evtl. bessere Strategien zu finden (Risiko).
* **Exploitation:** Das Wissen nutzen, das man schon hat, um Rewards zu sichern.

## 4. Arten von Algorithmen
* **Model-Free:** Der Agent lernt nur aus Erfahrung (Trial & Error).
    * *Beispiele:* Q-Learning, Policy Gradients (PPO, A3C).
* **Model-Based:** Der Agent lernt ein Modell der Umgebung und plant darin (√§hnlich zu [[Model Predictive Control]]).

---
**Links:** [[Pytorch Workflow]], [[Model Predictive Control]]